{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zIPD4QvxCmU"
   },
   "source": [
    "***\n",
    "# <font color=red>Chapter 6: MedTALN inc.'s Case Study -  Pre-Trained MLM Models Selection from Hugging Face</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by <font color=teal> John Doe (typica.ai) </font></p>\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "## Overview:\n",
    "\n",
    "This notebook guides you through the process of selecting a list of pre-trained models that suitable for our case study i.e. MLM supporting Healthcare domain and the French language that can be fine-tuned into a Healthcare NER model.\n",
    "\n",
    "This notebook will help us identify top-performing MLM models based on specific objective criteria.\n",
    "\n",
    "The notebook is structured into the following key steps:\n",
    "\n",
    "- **Search for MLM Models**: We begin by searching for candidate MLM models on the Hugging Face Hub that are suitable for our needs.\n",
    "- **Evaluate and Rank Models**: We evaluate the selected MLM models on a small, handcrafted dataset to determine which models best predict medical entities in the fill-mask task. The models are then ranked based on their performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the hugging face transformers library (the first time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters out warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPPF_IXEysAR"
   },
   "source": [
    "# Identify a list of candidate MLM models from Hugging Face Hub\n",
    "\n",
    "Search for Masked Language Models (MLM) suited for our  case study.\n",
    "\n",
    "We will use the Hugging Face Transformers Library to search and filter models programmatically\n",
    "\n",
    "\n",
    "1. Search Models : search for the MLM models supporting the french language  \n",
    "\n",
    "2. Filter found Models : filter out the returned models to retain only models supproting only french (monolangual) and have at least one of the healthcare domain related tags.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8C6dEY84Re-"
   },
   "source": [
    "## Search for MLM models\n",
    "We will use the Hugging Face Transformers Library to search and filter models programmatically\n",
    "\n",
    "Search Models : search for the MLM models supporting the french language\n",
    "\n",
    "Filter found Models : filter out the returned models to retain only models supproting only french (monolangual) and have at least one of the healthcare domain related tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AriF62DrakPN",
    "outputId": "955e4e76-9a4d-41e7-94e6-ea1740713d31",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr-BERT/DrBERT-4GB',\n",
       " 'Dr-BERT/DrBERT-7GB',\n",
       " 'Dr-BERT/DrBERT-4GB-CP-PubMedBERT',\n",
       " 'almanach/camembert-bio-base',\n",
       " 'Dr-BERT/DrBERT-7GB-Large',\n",
       " 'abazoge/DrLongformer',\n",
       " 'abazoge/DrBERT-4096',\n",
       " 'PantagrueLLM/jargon-general-base',\n",
       " 'PantagrueLLM/jargon-general-biomed',\n",
       " 'PantagrueLLM/jargon-biomed-4096',\n",
       " 'PantagrueLLM/jargon-multidomain-base',\n",
       " 'PantagrueLLM/jargon-biomed',\n",
       " 'PantagrueLLM/jargon-NACHOS',\n",
       " 'PantagrueLLM/jargon-NACHOS-4096']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_models\n",
    "\n",
    "# Fetch the list of models with the specified criteria\n",
    "models = list_models(\n",
    "    language =\"fr\", task=\"fill-mask\", library = \"pytorch\", cardData = True\n",
    ")\n",
    "\n",
    "\n",
    "# List of tags to filter by\n",
    "filter_tags = [\"healthcare\", \"medical\",  \"clinical\", \"biomedical\", \"biology\", \"life science\"]\n",
    "\n",
    "# Print the model IDs and some basic information\n",
    "included_models = []\n",
    "for model in models:\n",
    "    if  len(model.card_data.language) == 1 and \\\n",
    "        model.card_data.library_name == 'transformers' and \\\n",
    "        any(tag in model.tags for tag in filter_tags):\n",
    "\n",
    "      included_models.append(model.modelId)\n",
    "\n",
    "included_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB32bTGJ4INy"
   },
   "source": [
    "## Check the Models Configuration\n",
    "\n",
    "In this step, we validate that the selected models adhere to the architecture of the BERT base model, specifically with 12 hidden layers and 12 attention heads. This ensures consistency in terms of model size for our fine-tuned models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrry7Chht0LY",
    "outputId": "1285895e-fb6d-455f-b4c1-41a90e5cde0c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ed81787a894dc19cc3aa331b5c21ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46b1ea7c0fb4d37865a520b7489073b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b7a7e380e149b0bdd50693468830d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05a3e061f174554b180c4f2b27c40ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/710 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b34842d24a4492294c0a7b6b139a0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f5d30f16f948f6bf187aa3ccd68e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/979 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9786e34959e045d1ae10f365f64ab85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/980 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc7c857fd614a1dbbc0f685e5f16e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ecb550b9b04fd888095f4c3c631583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcbcd5273424feca5038b4f6fe3b61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5cb87387fd4a5888545c621a85b3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc78ea66afd842d6add8f582243d42bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9d1ca1f2cb44399e7efd228b74a5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e38ccb57394a7aab704e6c8d276d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Dr-BERT/DrBERT-4GB',\n",
       " 'Dr-BERT/DrBERT-7GB',\n",
       " 'Dr-BERT/DrBERT-4GB-CP-PubMedBERT',\n",
       " 'almanach/camembert-bio-base',\n",
       " 'abazoge/DrLongformer',\n",
       " 'abazoge/DrBERT-4096']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "# List of models to check\n",
    "model_ids = included_models\n",
    "# Initialize an empty dictionary to store model ID and their details\n",
    "models_with_right_config = []\n",
    "\n",
    "# Function to fetch the number of layers and attention heads\n",
    "def get_model_details(model_id):\n",
    "    try:\n",
    "        # Load the model configuration\n",
    "        config = AutoConfig.from_pretrained(model_id, trust_remote_code=False)\n",
    "\n",
    "        # Get the number of layers and attention heads\n",
    "        num_layers = config.num_hidden_layers\n",
    "        num_heads = config.num_attention_heads\n",
    "\n",
    "        return num_layers, num_heads\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving config for {model_id}: {e}\", None\n",
    "\n",
    "# Iterate through the models and populate the dictionary with their details\n",
    "for model_id in model_ids:\n",
    "    details = get_model_details(model_id)\n",
    "    if details[0] == 12 and details[1] == 12:\n",
    "      models_with_right_config.append(model_id)\n",
    "\n",
    "models_with_right_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwIx26dP6HFy"
   },
   "source": [
    "## Retrieve  Mask Tokens\n",
    "\n",
    "In this step, we retrieve the mask tokens for each of the models that retained models so far. Using the `AutoTokenizer` from the Hugging Face Transformers library, we load the tokenizer associated with each model and extract its mask token.\n",
    "\n",
    "We then validate that the mask token matches the expected tokens, specifically `\"[MASK]\"` or `\"<mask>\"`, which are commonly used in models like BERT and its variants. Models that meet this criterion are stored in the `models_with_mask_tokens` dictionary for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTN2wfbvimi-",
    "outputId": "7da8b1b8-e973-4d86-bddf-6b1ad1d53449",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabd225ef45842dd8a4e5d26619211f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/626 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768af65140d042b7a799fb89aa8ce74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/794k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6fae1af7c645c1be20841bb98045f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94548279ac0e438b97ae6f68fe20eef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/353 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fe70b1b98146cd9a69e58340e5650b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce52637680c04138bd279b8a37a7d815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/791k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9dba4864e446eea3cb0bf1ad44e99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc327931c6ed413aab1c1e114373c87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/353 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fa2ea7e18c411c9dfa739832631982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/496 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f24add2125c4eb2b3511744b499ef75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbc801c8cba405a9d40d9c22cd83355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/706k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe45accca6d47769d1311df290940cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39eca87f22740778264bed87ec4c590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b6ee3c0e08401d80c5d80f21bf23bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bd76c1c6e44f32bbdba3a786b91252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f7fd43d6454a1cb7476dbe63145cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/374 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5294e468ed541d8b4ad356ca9768482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/400 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd5a9f3ba404d888e75fc1d2b7e07ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6028703c2bed4afb88a6bacc238cd16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875f79ce4ae74c768eac5e567b55e2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3230020500c4e778f09a3c370fd6599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df543d321ad45698d5ecb3220fdaa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5958637b3f429ca1b3f881acba2f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/791k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e41a7ac915457cabe04c46664e6e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844bf3a3112246398582fbefd5b89a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/353 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Dr-BERT/DrBERT-4GB': '<mask>',\n",
       " 'Dr-BERT/DrBERT-7GB': '<mask>',\n",
       " 'Dr-BERT/DrBERT-4GB-CP-PubMedBERT': '[MASK]',\n",
       " 'almanach/camembert-bio-base': '<mask>',\n",
       " 'abazoge/DrLongformer': '<mask>',\n",
       " 'abazoge/DrBERT-4096': '<mask>'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize an empty dictionary to store model ID and mask token\n",
    "models_with_mask_tokens = {}\n",
    "\n",
    "# Function to fetch the mask token using the tokenizer\n",
    "def get_mask_token_via_tokenizer(model_id):\n",
    "    try:\n",
    "        # Load the tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "        # Get the mask token\n",
    "        return tokenizer.mask_token\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving tokenizer for {model_id}: {e}\"\n",
    "\n",
    "# Iterate through the models and populate the dictionary with mask tokens\n",
    "for model_id in models_with_right_config:\n",
    "    mask_token = get_mask_token_via_tokenizer(model_id)\n",
    "    if mask_token in [\"[MASK]\", \"<mask>\"]:\n",
    "        models_with_mask_tokens[model_id] = mask_token\n",
    "\n",
    "# Print the constructed dictionary\n",
    "models_with_mask_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_FL2IcY6oNJ"
   },
   "source": [
    "# Evaluate and Rank Models Based on Entity Prediction\n",
    "\n",
    "In this step, we evaluate a set of models to determine their effectiveness in predicting specific medical entities within masked sentences. Using the `fill-mask` pipeline from the Hugging Face Transformers library, each model is tested on a series of examples where key medical terms are masked.\n",
    "\n",
    "The models are scored based on how well their predictions match a combination of generic and specific expected entities. These scores are then aggregated to produce a cumulative score for each model. Finally, the models are ranked based on their cumulative scores, helping us identify the most effective model for our healthcare NER task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f_Eccqjjy4Q",
    "outputId": "ab7f5ec4-2c1a-42d9-a540-782ff87deeeb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dr-BERT/DrBERT-4GB ...\n",
      "Testing Dr-BERT/DrBERT-7GB ...\n",
      "Testing Dr-BERT/DrBERT-4GB-CP-PubMedBERT ...\n",
      "Testing almanach/camembert-bio-base ...\n",
      "Testing abazoge/DrLongformer ...\n",
      "Testing abazoge/DrBERT-4096 ...\n",
      "\n",
      "Model Ranking based on Weighted Entity Match Scores (top-5): \n",
      "1. Dr-BERT/DrBERT-4GB: Cumulative Score = 3.65\n",
      "2. abazoge/DrBERT-4096: Cumulative Score = 2.85\n",
      "3. Dr-BERT/DrBERT-7GB: Cumulative Score = 2.75\n",
      "4. almanach/camembert-bio-base: Cumulative Score = 2.5\n",
      "5. Dr-BERT/DrBERT-4GB-CP-PubMedBERT: Cumulative Score = 0.2\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Define the generic expected entities with their weights\n",
    "generic_expected_entities = [\n",
    "    {'médicaments': 0.3},\n",
    "    {'traitements': 0.3},\n",
    "    {'soins': 0.3},\n",
    "    {'remèdes': 0.3},\n",
    "    {'conseils': 0.1},\n",
    "    {'indications': 0.1},\n",
    "    {'instructions': 0.05},\n",
    "    {'interventions': 0.05},\n",
    "    {'compléments': 0.05}\n",
    "]\n",
    "\n",
    "\n",
    "# Define the examples and their specific expected entities\n",
    "examples = [\n",
    "    {\n",
    "        \"text\": \"Le medecin donne des {} en cas d'infections des voies respiratoires.\",\n",
    "        \"expected_entities\": [{'antibiotiques': 1}]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Le médecin recommande des {} pour réduire l'inflammation dans les poumons.\",\n",
    "        \"expected_entities\": [{'corticoïdes': 1}, {'anti-inflammatoires': 0.9}]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Pour soulager les symptômes d'allergie, le médecin prescrit des {}.\",\n",
    "        \"expected_entities\": [{'antihistaminiques': 1}]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Pour gérer le diabète, le médecin prescrit une {}.\",\n",
    "        \"expected_entities\": [{'insulinothérapie': 1}]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Après une blessure musculaire, le patient doit suivre une {}.\",\n",
    "        \"expected_entities\": [{'physiothérapie': 1}, {'rééducation': 0.8}]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"En cas d'infection bactérienne, le médecin recommande une {}.\",\n",
    "        \"expected_entities\": [{'antibiothérapie': 1}]\n",
    "    }\n",
    "]\n",
    "\n",
    "models = models_with_mask_tokens\n",
    "\n",
    "# Initialize a dictionary to store the cumulative scores for each model\n",
    "model_scores = {model_name: 0 for model_name in models}\n",
    "\n",
    "# Iterate over each model\n",
    "for model_name, mask_token in models.items():\n",
    "    print(f\"Testing {model_name} ...\")\n",
    "    try:\n",
    "      # Load the fill-mask pipeline for the current model\n",
    "      fill_mask = pipeline(\"fill-mask\", model=model_name, tokenizer=model_name, trust_remote_code=False)\n",
    "\n",
    "      # Iterate over each example\n",
    "      for example in examples:\n",
    "          # Prepare the example sentence with the correct mask token\n",
    "          masked_example = example[\"text\"].format(mask_token)\n",
    "          specific_expected_entities = example[\"expected_entities\"]\n",
    "\n",
    "          # Combine generic and specific entities, giving priority to specific ones\n",
    "          combined_expected_entities = {**{k: v for d in generic_expected_entities for k, v in d.items()}, **{k: v for d in specific_expected_entities for k, v in d.items()}}\n",
    "          # Get predictions\n",
    "          results = fill_mask(masked_example)\n",
    "\n",
    "          # Extract the top predicted tokens\n",
    "          predicted_tokens = [result['token_str'] for result in results]\n",
    "\n",
    "          # Calculate a score based on matching expected entities\n",
    "          score = 0\n",
    "          for entity, weight in combined_expected_entities.items():\n",
    "              if entity in predicted_tokens:\n",
    "                  score += weight\n",
    "\n",
    "          # Add the score to the cumulative score for the model\n",
    "          model_scores[model_name] += score\n",
    "            \n",
    "    except:\n",
    "      print(f\"Error in {model_name}\")\n",
    "\n",
    "# Rank models based on their cumulative scores\n",
    "ranked_models = sorted(model_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print the final ranking\n",
    "print(\"\\nModel Ranking based on Weighted Entity Match Scores (top-5): \")\n",
    "for rank, (model_name, score) in enumerate(ranked_models, 1):\n",
    "    #print only the top-5 models\n",
    "    if rank <= 5:\n",
    "      print(f\"{rank}. {model_name}: Cumulative Score = {score}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch21_p39_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch21_p39_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
