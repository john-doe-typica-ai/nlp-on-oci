{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e1cf01-6686-4fa2-b442-2821cbd5849e",
   "metadata": {},
   "source": [
    "### PII Model Saving and Deployment to Model Catalog\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed008256-775b-4cb0-b0a0-fe3a5a1c72ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e396c91b-2b19-41e8-9523-00caa17697a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328ebd1a-5874-49ae-9478-d5084799a7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary directory created at: /tmp/tmp0hj5lou2\n",
      "Written added_tokens.json to the temporary directory: /tmp/tmp0hj5lou2/added_tokens.json\n",
      "Written config.json to the temporary directory: /tmp/tmp0hj5lou2/config.json\n",
      "Written model.safetensors to the temporary directory: /tmp/tmp0hj5lou2/model.safetensors\n",
      "Written optimizer.pt to the temporary directory: /tmp/tmp0hj5lou2/optimizer.pt\n",
      "Written rng_state.pth to the temporary directory: /tmp/tmp0hj5lou2/rng_state.pth\n",
      "Written scheduler.pt to the temporary directory: /tmp/tmp0hj5lou2/scheduler.pt\n",
      "Written sentencepiece.bpe.model to the temporary directory: /tmp/tmp0hj5lou2/sentencepiece.bpe.model\n",
      "Written special_tokens_map.json to the temporary directory: /tmp/tmp0hj5lou2/special_tokens_map.json\n",
      "Written tokenizer.json to the temporary directory: /tmp/tmp0hj5lou2/tokenizer.json\n",
      "Written tokenizer_config.json to the temporary directory: /tmp/tmp0hj5lou2/tokenizer_config.json\n",
      "Written trainer_state.json to the temporary directory: /tmp/tmp0hj5lou2/trainer_state.json\n",
      "Written training_args.bin to the temporary directory: /tmp/tmp0hj5lou2/training_args.bin\n"
     ]
    }
   ],
   "source": [
    "import ocifs\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Initialize OCI File System\n",
    "fs = ocifs.OCIFileSystem()\n",
    "\n",
    "# Specify the object storage directory path\n",
    "#object_storage_path = \"taln_pii_cs_models@yz2wwgkgt8eh/taln_pii_cs_model_new/*\"\n",
    "object_storage_path = \"book_oci_nlp_training_bucket@yz2wwgkgt8eh/taln_pii_cs_model_trained-on-oci\"\n",
    "\n",
    "# List files in the object storage directory\n",
    "files = fs.glob(object_storage_path+\"/*\")\n",
    "\n",
    "# Create a temporary directory\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Temporary directory created at: {temp_dir}\")\n",
    "\n",
    "# Read from OCI Object Storage and write to the local temp directory\n",
    "for file_path in files:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    local_file_path = os.path.join(temp_dir, file_name)\n",
    "    \n",
    "    # Open the remote file and write its contents to a local file\n",
    "    with fs.open(file_path, 'rb') as remote_file, open(local_file_path, 'wb') as local_file:\n",
    "        local_file.write(remote_file.read())\n",
    "        print(f\"Written {file_name} to the temporary directory: {local_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53900f1d-7096-46f2-8d4f-e19feaa49537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model checkpoint: /tmp/tmp0hj5lou2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'FIRSTNAME',\n",
       "  'score': 0.6928959,\n",
       "  'word': 'Hicham,',\n",
       "  'start': 12,\n",
       "  'end': 19},\n",
       " {'entity_group': 'CREDITCARDNUMBER',\n",
       "  'score': 0.4786318,\n",
       "  'word': '4442223314488.',\n",
       "  'start': 90,\n",
       "  'end': 104}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "#model_checkpoint = \"./taln_pii_cs_models_local/taln_pii_cs_model\"\n",
    "model_checkpoint = temp_dir \n",
    "print(f\"model checkpoint: {model_checkpoint}\")\n",
    "\n",
    "data = \"Mon nom est Hicham, et pour l'anniversaire de 50 ans et je vais payer avec une carte visa 4442223314488.\"\n",
    "model = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"first\" #\"simple\"\n",
    ")\n",
    "preds = model(data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f77f92-ebd8-4939-a535-1dc00066a921",
   "metadata": {},
   "source": [
    "#### Prepare Model Artifact\n",
    "Instantiate a HuggingFacePipelineModel() object with HuggingFace pipelines. All the pipelines related files are saved under the artifact_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21368935-3fa3-4637-b617-ed1fef1ff0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model temp dir /tmp/tmp0hj5lou2 and the Model artifacts temp dir /tmp/tmp4rl_wqeo\n",
      "                                                                                                                                                                                              ?, ?it/s]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: TokenClassificationPipeline\n",
       "artifact_dir:\n",
       "  /tmp/tmp4rl_wqeo:\n",
       "  - - .model-ignore\n",
       "    - special_tokens_map.json\n",
       "    - tokenizer.json\n",
       "    - config.json\n",
       "    - runtime.yaml\n",
       "    - score.py\n",
       "    - model.safetensors\n",
       "    - sentencepiece.bpe.model\n",
       "    - added_tokens.json\n",
       "    - tokenizer_config.json\n",
       "framework: transformers\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.model import HuggingFacePipelineModel\n",
    "import tempfile\n",
    "\n",
    "#import oci\n",
    "#signer = oci.auth.signers.get_resource_principals_signer()\n",
    "ads.set_auth(auth='resource_principal')\n",
    "\n",
    "\n",
    "# Create a temporary directory\n",
    "artifacts_temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Model temp dir {temp_dir} and the Model artifacts temp dir {artifacts_temp_dir}\")\n",
    "\n",
    "# Prepare the model\n",
    "#artifact_dir = \"./taln_pii_cs_models\"\n",
    "huggingface_pipeline_model = HuggingFacePipelineModel(model, artifact_dir=artifacts_temp_dir)\n",
    "huggingface_pipeline_model.prepare(\n",
    "  inference_conda_env=\"oci://taln_pii_cs_conda_envs@yz2wwgkgt8eh/conda_environments/gpu/PyTorch 2.1 for GPU on Python 3.9/1.0/pytorch21_p39_gpu_v1\",\n",
    "  inference_python_version=\"3.9\",\n",
    "  training_conda_env=\"oci://taln_pii_cs_conda_envs@yz2wwgkgt8eh/conda_environments/gpu/PyTorch 2.1 for GPU on Python 3.9/1.0/pytorch21_p39_gpu_v1\",\n",
    "  use_case_type=UseCaseType.OTHER,\n",
    "  force_overwrite=True,\n",
    "  )\n",
    "# You don't need to modify the score.py generated. The model can be loaded by the transformers.pipeline.\n",
    "# More info here - https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61715d79-9ff8-4ff9-a6ea-cad1bff3adf0",
   "metadata": {},
   "source": [
    "#### Manually correct score.py\n",
    "\n",
    "- Go to terminal and open score.py e.g. (base) bash-4.2$ vim /tmp/tmpm81d8fz4/score.py\n",
    "- Add the following modifications\n",
    "\n",
    "1- In the method load_model, add a correction that introduces an aggregation_strategy parameter for pipeline, specifically set to \"first\"\n",
    "comment out the original line:\n",
    "```\n",
    "        # model = pipeline(task, model = model_dir)\n",
    "```\n",
    "Add the new lines below the commented line:\n",
    "```\n",
    "        #hicham's fix to add ner aggregation_strategy\n",
    "        model = pipeline(task, model = model_dir, aggregation_strategy=\"first\")\n",
    "```\n",
    "2- In the method serialize_prediction, add a correction that fixes the error \"The inference result is not json parsable Object of type float32 is not JSON serializable\"\n",
    "```   \n",
    "    #hicham's fix for the error \"The inference result is not json parsable Object of type float32 is not JSON serializable\" \n",
    "    if isinstance(yhat, dict):\n",
    "        for key, value in yhat.items():\n",
    "            if isinstance(value, np.float32):\n",
    "                yhat[key] = float(value)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd194092-cda7-484a-b1a9-1a4903b2cd7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmp4rl_wqeo/score.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the path to the source file (score_fixed.py) and the target location (/tmp/score.py)\n",
    "source_file = './score_fixed.py'  # Update with the actual path to score_fixed.py\n",
    "target_file = f'{artifacts_temp_dir}/score.py'\n",
    "\n",
    "# Copy the source file to the target location, effectively replacing it\n",
    "shutil.copyfile(source_file, target_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3231f726-087d-4a13-aba9-c4ea22612fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.model-ignore', 'special_tokens_map.json', 'tokenizer.json', 'config.json', 'runtime.yaml', 'score.py', 'model.safetensors', 'sentencepiece.bpe.model', 'added_tokens.json', 'tokenizer_config.json']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test key</th>\n",
       "      <th>Test name</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runtime_env_path</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runtime_env_python</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>runtime_path_exist</td>\n",
       "      <td>Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runtime_version</td>\n",
       "      <td>Check that field MODEL_ARTIFACT_VERSION is set to 3.0</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runtime_yaml</td>\n",
       "      <td>Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>score_load_model</td>\n",
       "      <td>Check that load_model() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>score_predict</td>\n",
       "      <td>Check that predict() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>score_predict_arg</td>\n",
       "      <td>Check that all other arguments in predict() are optional and have default values</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>score_predict_data</td>\n",
       "      <td>Check that the only required argument for predict() is named \"data\"</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>score_py</td>\n",
       "      <td>Check that the file \"score.py\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>score_syntax</td>\n",
       "      <td>Check for Python syntax errors</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test key  \\\n",
       "0     runtime_env_path   \n",
       "1   runtime_env_python   \n",
       "2   runtime_path_exist   \n",
       "3      runtime_version   \n",
       "4         runtime_yaml   \n",
       "5     score_load_model   \n",
       "6        score_predict   \n",
       "7    score_predict_arg   \n",
       "8   score_predict_data   \n",
       "9             score_py   \n",
       "10        score_syntax   \n",
       "\n",
       "                                                                                                Test name  \\\n",
       "0                                             Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set   \n",
       "1           Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher   \n",
       "2                             Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.   \n",
       "3                                                   Check that field MODEL_ARTIFACT_VERSION is set to 3.0   \n",
       "4   Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory   \n",
       "5                                                                      Check that load_model() is defined   \n",
       "6                                                                         Check that predict() is defined   \n",
       "7                        Check that all other arguments in predict() are optional and have default values   \n",
       "8                                     Check that the only required argument for predict() is named \"data\"   \n",
       "9       Check that the file \"score.py\" exists and is in the top level directory of the artifact directory   \n",
       "10                                                                         Check for Python syntax errors   \n",
       "\n",
       "    Result Message  \n",
       "0   Passed          \n",
       "1   Passed          \n",
       "2   Passed          \n",
       "3   Passed          \n",
       "4   Passed          \n",
       "5   Passed          \n",
       "6   Passed          \n",
       "7   Passed          \n",
       "8   Passed          \n",
       "9   Passed          \n",
       "10  Passed          "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_pipeline_model.introspect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83676a-27f7-4eb8-801a-1fd547b827ca",
   "metadata": {},
   "source": [
    "##### Call model summary\n",
    "The .summary_status() method returns a Pandas dataframe that guides you through the entire workflow. It shows which methods are available to call and which ones aren’t. Plus it outlines what each method does. If extra actions are required, it also shows those actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f3f1e78-1b36-4576-b130-6dbb554aa022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Available     Local tested .predict from score.py                               \n",
       "save()    Available     Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_pipeline_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2fcff-2797-4e66-93fd-7c50e4e08058",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Verify the generated model artifacts \n",
    "without deploying the model to model catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f19a39-6dd0-49a0-b661-46eb60151d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon nom est Hicham, et pour l'anniversaire de 50 ans et je vais payer avec une carte visa 4442223314488.\n",
      "Model is successfully loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': [{'entity_group': 'FIRSTNAME',\n",
       "   'score': 0.6928958892822266,\n",
       "   'word': 'Hicham,',\n",
       "   'start': 12,\n",
       "   'end': 19},\n",
       "  {'entity_group': 'CREDITCARDNUMBER',\n",
       "   'score': 0.47863179445266724,\n",
       "   'word': '4442223314488.',\n",
       "   'start': 90,\n",
       "   'end': 104}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data)\n",
    "huggingface_pipeline_model.verify(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b75144-732b-4436-826a-96b676239672",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8330d8c1-bc94-4a96-b4c5-3ec94c1310d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is successfully loaded.\n",
      "['.model-ignore', 'special_tokens_map.json', 'tokenizer.json', 'config.json', 'runtime.yaml', 'score.py', 'test_json_output.json', 'model.safetensors', 'sentencepiece.bpe.model', 'added_tokens.json', 'tokenizer_config.json']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Register the model\n",
    "\n",
    "model_id = huggingface_pipeline_model.save(display_name=\"TALN PII Case Study Model-pytorch12.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e93ce-8219-446f-b9ab-29e0f61b0d07",
   "metadata": {},
   "source": [
    "#### Deploy and Generate Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a00918c9-3692-41ef-b027-dfa5b9f25dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Deployment OCID: ocid1.datasciencemodeldeployment.oc1.ca-toronto-1.amaaaaaa3hvgr2qaaxmvgxthot7utyfjs7vins4a6faexn7fwkx56vna4mrq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating model deployment:   0%|          | [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://modeldeployment.ca-toronto-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.ca-toronto-1.amaaaaaa3hvgr2qaaxmvgxthot7utyfjs7vins4a6faexn7fwkx56vna4mrq\n"
     ]
    }
   ],
   "source": [
    "# Deploy and create an endpoint for the huggingface_pipeline_model\n",
    "huggingface_pipeline_model.deploy(\n",
    "    display_name=\"TALN PII Case Study Model-deployment-v12.0\", #HuggingFace Pipeline Model\n",
    "    description=\"TALN PII Case Study Model-deployment-pytorch12.0\",\n",
    "    deployment_log_group_id=\"ocid1.loggroup.oc1.ca-toronto-1.amaaaaaa3hvgr2qa4t42gdsnhm6ijpsfzhkizrzpp3cbfhvds2fnm2ejczaq\",\n",
    "    deployment_access_log_id=\"ocid1.log.oc1.ca-toronto-1.amaaaaaa3hvgr2qajbioaw6ru5o4hzt5q767rngzprsojfqemqvsoaa3cj6a\",\n",
    "    deployment_predict_log_id=\"ocid1.log.oc1.ca-toronto-1.amaaaaaa3hvgr2qajbioaw6ru5o4hzt5q767rngzprsojfqemqvsoaa3cj6a\",\n",
    "    # Shape config details mandatory for flexible shapes:\n",
    "    # deployment_instance_shape=\"VM.Standard.E4.Flex\",\n",
    "    # deployment_ocpus=<number>,\n",
    "    # deployment_memory_in_gbs=<number>,\n",
    ")\n",
    "print(f\"Endpoint: {huggingface_pipeline_model.model_deployment.url}\")\n",
    "# Output: \"Endpoint: https://modeldeployment.{region}.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.xxx.xxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c160447a-f046-488a-8d3f-ac2074a8a7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TALN PII Case Study Model-deployment-v12.0\n",
      "TALN PII Case Study Model-deployment-pytorch12.0\n",
      "2024-03-20 19:21:21.354000+00:00\n"
     ]
    }
   ],
   "source": [
    "print(huggingface_pipeline_model.model_deployment.display_name)\n",
    "print(huggingface_pipeline_model.model_deployment.description)\n",
    "print(huggingface_pipeline_model.model_deployment.time_created)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390ee17-8d9b-46f1-a317-069251136f99",
   "metadata": {},
   "source": [
    "### Run Prediction against Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd2130f3-282f-498d-b7e6-4f23f4415239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hicham, FIRSTNAME 0.6928958892822266 12 19\n",
      "4442223314488. CREDITCARDNUMBER 0.47863179445266724 90 104\n"
     ]
    }
   ],
   "source": [
    "# Generate prediction by invoking the deployed endpoint\n",
    "preds = huggingface_pipeline_model.predict(data)\n",
    "\n",
    "#print predictions\n",
    "for pred in preds['prediction']:\n",
    "    print(pred['word'],pred['entity_group'], pred['score'], pred['start'], pred['end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e9fc09c-d3c8-4e28-b790-5c765de7fd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction Endpoint: https://modeldeployment.ca-toronto-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.ca-toronto-1.amaaaaaa3hvgr2qaaxmvgxthot7utyfjs7vins4a6faexn7fwkx56vna4mrq/predict\n",
      "data : Mon nom est Hicham, et pour l'anniversaire de 50 ans et je vais payer avec une carte visa 4442223314488.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': [{'entity_group': 'FIRSTNAME',\n",
       "   'score': 0.6928958892822266,\n",
       "   'word': 'Hicham,',\n",
       "   'start': 12,\n",
       "   'end': 19},\n",
       "  {'entity_group': 'CREDITCARDNUMBER',\n",
       "   'score': 0.47863179445266724,\n",
       "   'word': '4442223314488.',\n",
       "   'start': 90,\n",
       "   'end': 104}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The OCI SDK must be installed for this example to function properly.\n",
    "# Installation instructions can be found here: https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/pythonsdk.htm\n",
    "\n",
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer\n",
    "\n",
    "config = oci.config.from_file(\"~/.oci/config\") # replace with the location of your oci config file\n",
    "auth = Signer(\n",
    "  tenancy=config['tenancy'],\n",
    "  user=config['user'],\n",
    "  fingerprint=config['fingerprint'],\n",
    "  private_key_file_location=config['key_file'],\n",
    "  pass_phrase=config['pass_phrase'])\n",
    "\n",
    "prediction_endpoint = f'{huggingface_pipeline_model.model_deployment.url}/predict'\n",
    "\n",
    "print(f\"Model Prediction Endpoint: {prediction_endpoint}\")\n",
    "print(f\"data : {data}\")\n",
    "\n",
    "body = {\"inputs\":data} # payload goes here\n",
    "headers = {} # header goes here\n",
    "\n",
    "preds = requests.post(prediction_endpoint, json=body, auth=auth, headers=headers).json()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d70497-7570-4017-bd82-d32f57455045",
   "metadata": {},
   "source": [
    "#### To do:\n",
    "1- Troubleshoot why deployment fails without this policy :\n",
    "- Allow any-user to read objects in compartment book_oci_nlp\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch21_p39_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch21_p39_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
